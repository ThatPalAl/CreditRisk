{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21d2229",
   "metadata": {},
   "source": [
    "Dataset Class:\n",
    "\n",
    "While building a pytorch model it's crucial to have something that gives us samples from our dataset. That's what the dataset class is for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b9ca40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38eacdc",
   "metadata": {},
   "source": [
    "One way of doing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "902f606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(torch.utils.data.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462ed34",
   "metadata": {},
   "source": [
    "But we won't be doing that. We will write our own custom dataset class. No imports required then.\n",
    "\n",
    "It needs:\n",
    "- to consist a constructor (init)\n",
    "- size calculator (len)\n",
    "- function that takes an index and returns it's value (get item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_sample = self.data[idx, :] #assuming we rely on numpy array - tabular dataset\n",
    "        current_target = self.targets[idx] #also 1d array or a list of values - if we would have multiple targets: self.targets[idx, :]\n",
    "        return {\n",
    "            \"sample\" : torch.tensor(current_sample, dtype=torch.float),\n",
    "            \"target\" : torch.tensor(current_target, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f070e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "make_classification(\n",
      "    n_samples=\u001b[32m100\u001b[39m,\n",
      "    n_features=\u001b[32m20\u001b[39m,\n",
      "    *,\n",
      "    n_informative=\u001b[32m2\u001b[39m,\n",
      "    n_redundant=\u001b[32m2\u001b[39m,\n",
      "    n_repeated=\u001b[32m0\u001b[39m,\n",
      "    n_classes=\u001b[32m2\u001b[39m,\n",
      "    n_clusters_per_class=\u001b[32m2\u001b[39m,\n",
      "    weights=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    flip_y=\u001b[32m0.01\u001b[39m,\n",
      "    class_sep=\u001b[32m1.0\u001b[39m,\n",
      "    hypercube=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    shift=\u001b[32m0.0\u001b[39m,\n",
      "    scale=\u001b[32m1.0\u001b[39m,\n",
      "    shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    random_state=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    return_X_y=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Generate a random n-class classification problem.\n",
      "\n",
      "This initially creates clusters of points normally distributed (std=1)\n",
      "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "class. It introduces interdependence between these features and adds\n",
      "various types of further noise to the data.\n",
      "\n",
      "Without shuffling, ``X`` horizontally stacks features in the following\n",
      "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "linear combinations of the informative features, followed by ``n_repeated``\n",
      "duplicates, drawn randomly with replacement from the informative and\n",
      "redundant features. The remaining features are filled with random noise.\n",
      "Thus, without shuffling, all useful features are contained in the columns\n",
      "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int, default=100\n",
      "    The number of samples.\n",
      "\n",
      "n_features : int, default=20\n",
      "    The total number of features. These comprise ``n_informative``\n",
      "    informative features, ``n_redundant`` redundant features,\n",
      "    ``n_repeated`` duplicated features and\n",
      "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "    drawn at random.\n",
      "\n",
      "n_informative : int, default=2\n",
      "    The number of informative features. Each class is composed of a number\n",
      "    of gaussian clusters each located around the vertices of a hypercube\n",
      "    in a subspace of dimension ``n_informative``. For each cluster,\n",
      "    informative features are drawn independently from  N(0, 1) and then\n",
      "    randomly linearly combined within each cluster in order to add\n",
      "    covariance. The clusters are then placed on the vertices of the\n",
      "    hypercube.\n",
      "\n",
      "n_redundant : int, default=2\n",
      "    The number of redundant features. These features are generated as\n",
      "    random linear combinations of the informative features.\n",
      "\n",
      "n_repeated : int, default=0\n",
      "    The number of duplicated features, drawn randomly from the informative\n",
      "    and the redundant features.\n",
      "\n",
      "n_classes : int, default=2\n",
      "    The number of classes (or labels) of the classification problem.\n",
      "\n",
      "n_clusters_per_class : int, default=2\n",
      "    The number of clusters per class.\n",
      "\n",
      "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "    The proportions of samples assigned to each class. If None, then\n",
      "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "    then the last class weight is automatically inferred.\n",
      "    More than ``n_samples`` samples may be returned if the sum of\n",
      "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "\n",
      "flip_y : float, default=0.01\n",
      "    The fraction of samples whose class is assigned randomly. Larger\n",
      "    values introduce noise in the labels and make the classification\n",
      "    task harder. Note that the default setting flip_y > 0 might lead\n",
      "    to less than ``n_classes`` in y in some cases.\n",
      "\n",
      "class_sep : float, default=1.0\n",
      "    The factor multiplying the hypercube size.  Larger values spread\n",
      "    out the clusters/classes and make the classification task easier.\n",
      "\n",
      "hypercube : bool, default=True\n",
      "    If True, the clusters are put on the vertices of a hypercube. If\n",
      "    False, the clusters are put on the vertices of a random polytope.\n",
      "\n",
      "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "    Shift features by the specified value. If None, then features\n",
      "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "\n",
      "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "    Multiply features by the specified value. If None, then features\n",
      "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "    happens after shifting.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples and the features.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "return_X_y : bool, default=True\n",
      "    If True, a tuple ``(X, y)`` instead of a Bunch object is returned.\n",
      "\n",
      "    .. versionadded:: 1.7\n",
      "\n",
      "Returns\n",
      "-------\n",
      "data : :class:`~sklearn.utils.Bunch` if `return_X_y` is `False`.\n",
      "    Dictionary-like object, with the following attributes.\n",
      "\n",
      "    DESCR : str\n",
      "        A description of the function that generated the dataset.\n",
      "    parameter : dict\n",
      "        A dictionary that stores the values of the arguments passed to the\n",
      "        generator function.\n",
      "    feature_info : list of len(n_features)\n",
      "        A description for each generated feature.\n",
      "    X : ndarray of shape (n_samples, n_features)\n",
      "        The generated samples.\n",
      "    y : ndarray of shape (n_samples,)\n",
      "        An integer label for class membership of each sample.\n",
      "\n",
      "    .. versionadded:: 1.7\n",
      "\n",
      "(X, y) : tuple if ``return_X_y`` is True\n",
      "    A tuple of generated samples and labels.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_blobs : Simplified variant.\n",
      "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "the \"Madelon\" dataset.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "       selection benchmark\", 2003.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import make_classification\n",
      ">>> X, y = make_classification(random_state=42)\n",
      ">>> X.shape\n",
      "(100, 20)\n",
      ">>> y.shape\n",
      "(100,)\n",
      ">>> list(y[:5])\n",
      "[np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0)]\n",
      "\u001b[31mFile:\u001b[39m      ~/Documents/Projects/CreditRisk/venv_credit_risk/lib/python3.12/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "?make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fa925a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b6cc40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc507512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "792f0e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16979023,  0.10691182,  0.30414502, ...,  1.0626695 ,\n",
       "        -0.29436545, -1.10699998],\n",
       "       [ 0.32425587, -0.32573108,  0.17012535, ...,  0.08461653,\n",
       "        -1.45996237, -0.13193471],\n",
       "       [-0.68078443,  0.05358512,  1.10849775, ...,  0.43914515,\n",
       "        -0.43305859,  1.24266871],\n",
       "       ...,\n",
       "       [-0.62086795, -0.61069116, -0.07145637, ..., -0.62541193,\n",
       "         1.88244595, -2.53305355],\n",
       "       [ 1.15202562, -0.72934549,  0.02442004, ...,  0.38376808,\n",
       "        -0.96925367,  0.35392736],\n",
       "       [-1.70521712,  0.88608599, -1.478207  , ..., -1.56631137,\n",
       "        -0.01758584, -0.20728131]], shape=(1000, 20))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5744e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(data=data, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "353203d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16979023,  0.10691182,  0.30414502, ...,  1.0626695 ,\n",
       "        -0.29436545, -1.10699998],\n",
       "       [ 0.32425587, -0.32573108,  0.17012535, ...,  0.08461653,\n",
       "        -1.45996237, -0.13193471],\n",
       "       [-0.68078443,  0.05358512,  1.10849775, ...,  0.43914515,\n",
       "        -0.43305859,  1.24266871],\n",
       "       ...,\n",
       "       [-0.62086795, -0.61069116, -0.07145637, ..., -0.62541193,\n",
       "         1.88244595, -2.53305355],\n",
       "       [ 1.15202562, -0.72934549,  0.02442004, ...,  0.38376808,\n",
       "        -0.96925367,  0.35392736],\n",
       "       [-1.70521712,  0.88608599, -1.478207  , ..., -1.56631137,\n",
       "        -0.01758584, -0.20728131]], shape=(1000, 20))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15e5376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5542f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CustomDataset.__len__ of <__main__.CustomDataset object at 0x13755f590>>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset.__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "92b1d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1be45369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([ 0.1698,  0.1069,  0.3041, -0.2440, -1.4553, -0.7016, -0.8871,  1.2583,\n",
       "         -1.8462, -2.4219,  1.0927,  0.1537, -0.6797, -0.7101, -1.3596,  2.2179,\n",
       "         -0.5649,  1.0627, -0.2944, -1.1070]),\n",
       " 'target': tensor(1)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f70dc4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0][\"sample\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50d330c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1698,  0.1069,  0.3041, -0.2440, -1.4553, -0.7016, -0.8871,  1.2583,\n",
       "        -1.8462, -2.4219,  1.0927,  0.1537, -0.6797, -0.7101, -1.3596,  2.2179,\n",
       "        -0.5649,  1.0627, -0.2944, -1.1070])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0][\"sample\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "53c9cd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0][\"target\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d0787b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0][\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e7210",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db04fd7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_credit_risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
